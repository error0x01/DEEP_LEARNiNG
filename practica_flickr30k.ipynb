{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practica.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [
        "M_8zVgQ6g_Sl",
        "HLlkJu7LVhBE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "q9bJSv3IOhhQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notas para la práctica"
      ]
    },
    {
      "metadata": {
        "id": "_QrPOc4yNbBs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lo que tenemos que hacer es entender el ejemplo, e intentar mejoraro. Por mejorarlo entiendo, por ejemplo, lo siguiente:\n",
        "   - cambiar la CNN de VGG16 a otro tipo\n",
        "   - encontrar buenos parámetros (no hacer un grid seach, recomendacion del profe)\n",
        "   - jugar con la LSTM a ver si conseguimos que de mejores resultados... \n",
        "   - Como guinda al pastel, si utilizamos otro dataset diferente, pues también estaría bien. \n",
        "   \n",
        "PROFE:\n",
        "Como veo que hay algunas dudas con respecto a la práctica, os comento por aquí lo que espero que hagáis.El ejemplo que os proporciono es tremendamente sencillo y, como podéis comprobar, no funciona ni mucho menos de una forma aceptable. Así que una cosa que podéis hacer es seguir con ese ejemplo y cambiar el dataset, jugar con los parámetros (no recomendaría un grid search, acordaos de que hay formas mejores de hacerlo :wink: ), etc.Ahora bien, lo que yo os aconsejo que hagáis es que miréis en los ejemplos que os adjunté al final del notebook (u otros que encontréis vosotros) donde se explican con ejemplos diferentes arquitecturas y enfoques, que escojáis uno de ellos y que tratéis de hacerlo funcionar. Eso lo primero, y después, que miréis otros ejemplos para combinarlos con lo que ya tenéis e intentar mejorar lo que conseguís. \n",
        "   \n",
        "PROFE 2: \n",
        "Según podéis ver, las descripciones que damos de nuestras imágenes no son las más precisas del mundo. Esto es porque este ejemplo usa muy pocos datos, en la FUENTE que tenéis más abajo, que es de donde he extraído este ejemplo, podéis ver cómo mejoran lo que hemos hecho aquí.\n",
        "\n",
        "FUENTE: https://machinelearningmastery.com/develop-a-caption-generation-model-in-keras/\n",
        "\n",
        "Os dejo también varios enlaces que podéis consultar para conseguir hacer algo mejor todavía:\n",
        "\n",
        "    https://machinelearningmastery.com/how-to-caption-photos-with-deep-learning/\n",
        "    https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/\n",
        "    https://daniel.lasiman.com/post/image-captioning/\n",
        "    https://www.oreilly.com/learning/caption-this-with-tensorflow\n",
        "    https://towardsdatascience.com/image-captioning-in-deep-learning-9cd23fb4d8d2\n",
        "    https://deeplearningmania.quora.com/Keras-deep-learning-for-image-caption-retrieval\n",
        "\n",
        "Todos ellos son muy didácticos y os van a servir de mucho a la hora de hacer la práctica. Lamento no poder proporcionaros material en español, pero desgraciadamente este mundo evoluciona muy rápido y lo mejor está siempre en inglés. Lo único que puedo deciros es que estamos trabajando en solucionar esto, y en unos meses esperamos tener un blog donde proporcionar ejemplos de alto nivel, de forma didáctica y a la vez compleja, en un perfecto castellano manchego. Si estáis interesados decidmelo y en cuanto lo lancemos os lo haremos saber!\n"
      ]
    },
    {
      "metadata": {
        "id": "M_8zVgQ6g_Sl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Descarga del fichero flickr30k con las descripciones de las imágnes"
      ]
    },
    {
      "metadata": {
        "id": "zldCTise06jj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "0cda17e1-3e29-4c31-b2a6-076af9f65300",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530210250433,
          "user_tz": -120,
          "elapsed": 2178,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://shannon.cs.illinois.edu/DenotationGraph/data/flickr30k.tar.gz\n",
        " "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-28 18:24:09--  http://shannon.cs.illinois.edu/DenotationGraph/data/flickr30k.tar.gz\n",
            "Resolving shannon.cs.illinois.edu (shannon.cs.illinois.edu)... 192.17.90.133\n",
            "Connecting to shannon.cs.illinois.edu (shannon.cs.illinois.edu)|192.17.90.133|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3652513 (3.5M) [application/x-gzip]\n",
            "Saving to: ‘flickr30k.tar.gz’\n",
            "\n",
            "flickr30k.tar.gz    100%[===================>]   3.48M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2018-06-28 18:24:09 (30.8 MB/s) - ‘flickr30k.tar.gz’ saved [3652513/3652513]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RicwfFhd4OGD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "0ba9acc7-ffa7-4a92-8baa-aba9ff2562bc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530210293597,
          "user_tz": -120,
          "elapsed": 2278,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 3604\r\n",
            "drwxr-xr-x 1 root root    4096 Jun 28 18:24 .\r\n",
            "drwxr-xr-x 1 root root    4096 Jun 28 18:22 ..\r\n",
            "drwx------ 4 root root    4096 Jun 28 18:23 .cache\r\n",
            "drwxr-xr-x 3 root root    4096 Jun 28 18:23 .config\r\n",
            "drwxr-xr-x 3 root root    4096 Jun 25 16:59 datalab\r\n",
            "-rw-r--r-- 1 root root 3652513 Sep 21  2015 flickr30k.tar.gz\r\n",
            "drwxr-xr-x 4 root root    4096 Jun 28 18:23 .forever\r\n",
            "drwxr-xr-x 5 root root    4096 Jun 28 18:23 .ipython\r\n",
            "drwx------ 3 root root    4096 Jun 28 18:23 .local\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "38ZL5DnKPAXc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1edc486c-a7fe-4bda-d7e4-27fd196b16af",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530210297309,
          "user_tz": -120,
          "elapsed": 1952,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!tar -tvf flickr30k.tar.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- pyoung2/14987   682 2013-12-24 09:29 readme.txt\r\n",
            "-rw-r--r-- pyoung2/pyoung2 13023677 2013-12-16 18:20 results_20130124.token\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "znCTJARgQNIu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ab1f8800-a321-4f18-9816-c34643cd9465",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530210427277,
          "user_tz": -120,
          "elapsed": 2213,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!tar -zxvf flickr30k.tar.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "readme.txt\r\n",
            "results_20130124.token\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R_Kn4-t8RWyl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "6774a65c-9cfa-4644-9c5d-34d548234a71",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530210446205,
          "user_tz": -120,
          "elapsed": 2078,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!grep 405961988 results_20130124.token"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "405961988.jpg#0\tThe construction worker is drilling into the street near a street with active traffic .\r\n",
            "405961988.jpg#1\tThe man in the construction gear uses a large , red drill .\r\n",
            "405961988.jpg#2\tA man wearing a hi-viz jacket is drilling into the road .\r\n",
            "405961988.jpg#3\tA construction worker drills a hole into the ground .\r\n",
            "405961988.jpg#4\tA man wearing a yellow vest works in the street .\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HLlkJu7LVhBE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepararmos los datos mediante las funciones axiliares faciliadas en el curso. \n",
        "*Mi \"aportación\" en este punto ha  sido entender el código por completo y documentar aquellas funciones que desconocía:*"
      ]
    },
    {
      "metadata": {
        "id": "96oGKInUVXJd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Carga el contenido de un fichero en una variable para trabajar con ella\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        " \n",
        "filename = 'results_20130124.token'\n",
        "# load descriptions\n",
        "doc = load_doc(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "orjy0N-RWgau",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "1d489966-ed02-4864-950c-0d251ec2d5ca",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530210478920,
          "user_tz": -120,
          "elapsed": 908,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Datos relativos al fichero \" + filename + \" cargados en 'doc'\")\n",
        "print('Tipo de fichero: %s ' % type(doc))\n",
        "print('Longitud del fichero: %d ' % len(doc))\n",
        "print(\"200 primeros carcteres:\")\n",
        "doc[:200].split('\\n')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datos relativos al fichero results_20130124.token cargados en 'doc'\n",
            "Tipo de fichero: <class 'str'> \n",
            "Longitud del fichero: 13023667 \n",
            "200 primeros carcteres:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1000092795.jpg#0\\tTwo young guys with shaggy hair look at their hands while hanging out in the yard .',\n",
              " '1000092795.jpg#1\\tTwo young , White males are outside near many bushes .',\n",
              " '1000092795.jpg#2\\tTwo men in']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "6uVjdMtubOZ8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "42a3e661-0066-409a-8f00-5be48b8e2705",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530210486051,
          "user_tz": -120,
          "elapsed": 1795,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# extract descriptions for images\n",
        "# sólo se almacenará la primera descripción de cada imagen\n",
        "def load_descriptions(doc):\n",
        "\tmapping = dict()\n",
        "\t# process lines\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "    # Si la linea tiene 2 o menos caracteres se descarta y se selecciona la siguiente\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\t# take the first token as the image id (tokens[0]), the rest as the description (tokens[1:])\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# remove extension from image id\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\t# convert description tokens back to string\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\t# store the first description for each image in a dictionary\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = image_desc\n",
        "\treturn mapping\n",
        " \n",
        "# parse descriptions\n",
        "descriptions = load_descriptions(doc)\n",
        "print('Descripcion de la imagen \"1000092795\": %s' % descriptions['1000092795'])\n",
        "print('Loaded: %d ' % len(descriptions))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Descripcion de la imagen \"1000092795\": Two young guys with shaggy hair look at their hands while hanging out in the yard .\n",
            "Loaded: 31783 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dDT9vi_fcwTf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para \"limpiar\" los mensajes se convierten todas las palabras a minúsculas, se quitan los signos de puntuación así como las palabras de 1 solo caracter"
      ]
    },
    {
      "metadata": {
        "id": "TuSKX8OVcrKg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d3d719a9-d095-44d3-fa1d-69f80521e7a0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530210492636,
          "user_tz": -120,
          "elapsed": 1077,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def clean_descriptions(descriptions):\n",
        "  \n",
        "  # str.maketrans('', '', string.punctuation)\n",
        "  # This uses the 3-argument version of str.maketrans\n",
        "  # with arguments (x, y, z) where 'x' and 'y'\n",
        "  # must be equal-length strings and characters in 'x'\n",
        "  # are replaced by characters in 'y'. 'z'\n",
        "  # is a string (string.punctuation here)\n",
        "  # where each character in the string is mapped to None\n",
        "\n",
        "\t# prepare translation table for removing punctuation\t\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  # descriptions.items() son los distintos elementos del diccionario\n",
        "  for key, desc in descriptions.items():\n",
        "\t\t# tokenize: pasa el string de la descripción a una lista de palabras\n",
        "    desc = desc.split()\n",
        "\t\t# convert to lower case\n",
        "    desc = [word.lower() for word in desc]\n",
        "\t\t# remove punctuation from each token: Aquí aplicamos la tabla anterior\n",
        "    desc = [w.translate(table) for w in desc]\n",
        "\t\t# remove hanging 's' and 'a'\n",
        "    desc = [word for word in desc if len(word)>1]\n",
        "\t\t# store as string\n",
        "    descriptions[key] =  ' '.join(desc)\n",
        "\n",
        "# clean descriptions\n",
        "clean_descriptions(descriptions)\n",
        "# summarize vocabulary: número de palabras\n",
        "all_tokens = ' '.join(descriptions.values()).split()\n",
        "vocabulary = set(all_tokens)\n",
        "print('Descripcion de la imagen \"1000092795\": %s' % descriptions['1000092795'])\n",
        "print('Vocabulary Size: %d' % len(vocabulary))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Descripcion de la imagen \"1000092795\": two young guys with shaggy hair look at their hands while hanging out in the yard\n",
            "Vocabulary Size: 13130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZmiOSWnidwdU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Guardamos el dataset modificado"
      ]
    },
    {
      "metadata": {
        "id": "amN1uDKRdlpt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# save descriptions to file, one per line\n",
        "def save_doc(descriptions, filename):\n",
        "\tlines = list()\n",
        "\tfor key, desc in descriptions.items():\n",
        "\t\tlines.append(key + ' ' + desc)\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()\n",
        "\n",
        "# save descriptions\n",
        "save_doc(descriptions, 'descriptions.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJyPQfWoeRf-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "f7962b7d-89f1-4353-f3c8-d49f8ed99876",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530210533415,
          "user_tz": -120,
          "elapsed": 771,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Datos relativos al fichero \" + filename + \" cargados en 'doc'\")\n",
        "print('Tipo de fichero: %s ' % type(descriptions))\n",
        "print('Longitud del fichero: %d ' % len(descriptions))\n",
        "print('Descripcion de la imagen \"1000092795\": %s' % descriptions['1000092795'])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datos relativos al fichero results_20130124.token cargados en 'doc'\n",
            "Tipo de fichero: <class 'dict'> \n",
            "Longitud del fichero: 31783 \n",
            "Descripcion de la imagen \"1000092795\": two young guys with shaggy hair look at their hands while hanging out in the yard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z29Bsvivgb5i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preparación de las imágenes"
      ]
    },
    {
      "metadata": {
        "id": "2iDefXFE5Mab",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "0e4ca21c-5f93-484f-9a7a-d3dcb94f9e5a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530351850411,
          "user_tz": -120,
          "elapsed": 51501,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://shannon.cs.illinois.edu/DenotationGraph/data/flickr30k-images.tar"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-30 09:43:20--  http://shannon.cs.illinois.edu/DenotationGraph/data/flickr30k-images.tar\n",
            "Resolving shannon.cs.illinois.edu (shannon.cs.illinois.edu)... 192.17.90.133\n",
            "Connecting to shannon.cs.illinois.edu (shannon.cs.illinois.edu)|192.17.90.133|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4440780800 (4.1G) [application/x-tar]\n",
            "Saving to: ‘flickr30k-images.tar’\n",
            "\n",
            "flickr30k-images.ta  85%[================>   ]   3.53G  87.9MB/s    eta 8s     "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "flickr30k-images.ta 100%[===================>]   4.14G  89.0MB/s    in 49s     \n",
            "\n",
            "2018-06-30 09:44:09 (85.7 MB/s) - ‘flickr30k-images.tar’ saved [4440780800/4440780800]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uDWJIDt-5SxV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!tar -xf flickr30k-images.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIrbgMQuOtAq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "9f73eaf9-69da-46ee-a13f-85651cedef16",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530352094725,
          "user_tz": -120,
          "elapsed": 2208,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4337780\r\n",
            "drwxr-xr-x 1 root root        4096 Jun 30 09:46 .\r\n",
            "drwxr-xr-x 1 root root        4096 Jun 30 09:38 ..\r\n",
            "drwx------ 4 root root        4096 Jun 30 09:42 .cache\r\n",
            "drwxr-xr-x 3 root root        4096 Jun 30 09:42 .config\r\n",
            "drwxr-xr-x 3 root root        4096 Jun 28 16:55 datalab\r\n",
            "drwxr-xr-x 2  501 staff    1060864 Jan 15  2014 flickr30k-images\r\n",
            "-rw-r--r-- 1 root root  4440780800 Sep 21  2015 flickr30k-images.tar\r\n",
            "drwxr-xr-x 4 root root        4096 Jun 30 09:39 .forever\r\n",
            "drwxr-xr-x 5 root root        4096 Jun 30 09:42 .ipython\r\n",
            "drwx------ 3 root root        4096 Jun 30 09:39 .local\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QvpIYarr_RRE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "3896278f-01dc-470b-cb8e-9b72aa92c4c7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530352103608,
          "user_tz": -120,
          "elapsed": 3265,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# https://pypi.org/project/tqdm/\n",
        "# tqdm means “progress” in Arabic, Instantly make your loops show a smart progress meter - just wrap any iterable with tqdm(iterable), and you’re done!\n",
        "!pip install tqdm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.23.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S3z9RwWFjGe8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8a472b4-2495-41ef-fdc1-5fdaf50fca9c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530352116250,
          "user_tz": -120,
          "elapsed": 10092,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from pickle import load, dump\n",
        "from tqdm import tqdm\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from pandas import DataFrame\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, LSTM, RepeatVector, TimeDistributed, Embedding\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.pooling import GlobalMaxPooling2D"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qp9A4U7n0r0D",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "43ce66bc-4c5c-48d4-f2af-3e9c7add5aab",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530352121167,
          "user_tz": -120,
          "elapsed": 2989,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls flickr30k-images/|grep readme\n",
        "!rm flickr30k-images/readme.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "readme.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BNGDtta_JcAB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "a211d7bb-8489-47b5-c0e8-ba5fa7ac2114",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530353260074,
          "user_tz": -120,
          "elapsed": 1092479,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# extract features from each photo in the directory\n",
        "def extract_features(directory):\n",
        "  # load the model\n",
        "  in_layer = Input(shape=(224, 224, 3))\n",
        "  model = VGG16(include_top=False, input_tensor=in_layer)\n",
        "  print(model.summary())\n",
        "  # extract features from each photo\n",
        "  features = dict()\n",
        "  files_in_directory = listdir(directory)\n",
        "  n_images = len(files_in_directory)\n",
        "  for i, name in tqdm(enumerate(files_in_directory)):\n",
        "    # load an image from file\n",
        "    filename = directory + '/' + name\n",
        "    image = load_img(filename, target_size=(224, 224))\n",
        "    # convert the image pixels to a numpy array\n",
        "    image = img_to_array(image)\n",
        "    # reshape data for the model\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    # prepare the image for the VGG model\n",
        "    image = preprocess_input(image)\n",
        "    # get features\n",
        "    feature = model.predict(image, verbose=0)\n",
        "    # get image id\n",
        "    image_id = name.split('.')[0]\n",
        "    # store feature\n",
        "    features[image_id] = feature\n",
        "    # print('{} / {} > {}'.format(i, n_images, name))\n",
        "  return features\n",
        "\n",
        "# extract features from all images\n",
        "directory = 'flickr30k-images'\n",
        "features = extract_features(directory)\n",
        "print('Extracted Features: %d' % len(features))\n",
        "# save to file\n",
        "# dump(features, open('features.pkl', 'wb'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "31783it [18:09, 29.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracted Features: 31783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wzSYST74xZuw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "17c87585-fc87-43af-8d04-71dfc5f78fcd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530223389535,
          "user_tz": -120,
          "elapsed": 1913,
          "user": {
            "displayName": "joe doe",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111551388537557126807"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 32\r\n",
            "drwxr-xr-x 1 root root 4096 Jun 28 22:02 .\r\n",
            "drwxr-xr-x 1 root root 4096 Jun 28 21:30 ..\r\n",
            "drwx------ 4 root root 4096 Jun 28 22:02 .cache\r\n",
            "drwxr-xr-x 3 root root 4096 Jun 28 22:02 .config\r\n",
            "drwxr-xr-x 3 root root 4096 Jun 25 16:59 datalab\r\n",
            "drwxr-xr-x 4 root root 4096 Jun 28 21:31 .forever\r\n",
            "drwxr-xr-x 5 root root 4096 Jun 28 22:02 .ipython\r\n",
            "drwx------ 3 root root 4096 Jun 28 21:31 .local\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V9D4Nw1AJ9SU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load a pre-defined list of photo identifiers\n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\t# process line by line\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# skip empty lines\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\t# get the image identifier\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        "\n",
        "# split a dataset into train/test elements\n",
        "def train_test_split(dataset):\n",
        "\t# order keys so the split is consistent\n",
        "\tordered = sorted(dataset)\n",
        "\t# return split dataset as two new sets\n",
        "\treturn set(ordered[:100]), set(ordered[100:200])\n",
        "\n",
        "# load clean descriptions into memory\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "\t# load document\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\t# split id from description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# skip images not in the set\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\t# store\n",
        "\t\t\tdescriptions[image_id] = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\treturn descriptions\n",
        "\n",
        "# load photo features\n",
        "def load_photo_features(filename, dataset):\n",
        "\t# load all features\n",
        "\tall_features = load(open(filename, 'rb'))\n",
        "\t# filter features\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features\n",
        "\n",
        "# load dev set\n",
        "filename = 'Flickr_8k.devImages.txt'\n",
        "dataset = load_set(filename)\n",
        "print('Dataset: %d' % len(dataset))\n",
        "# train-test split\n",
        "train, test = train_test_split(dataset)\n",
        "print('Train=%d, Test=%d' % (len(train), len(test)))\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
        "print('Descriptions: train=%d, test=%d' % (len(train_descriptions), len(test_descriptions)))\n",
        "# photo features\n",
        "train_features = load_photo_features('features.pkl', train)\n",
        "test_features = load_photo_features('features.pkl', test)\n",
        "print('Photos: train=%d, test=%d' % (len(train_features), len(test_features)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S8t8GxnRKDvO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Ahora codificamos nuestras descripciones a números\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# fit a tokenizer given caption descriptions\n",
        "def create_tokenizer(descriptions):\n",
        "\tlines = list(descriptions.values())\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        " \n",
        "# prepare tokenizer\n",
        "tokenizer = create_tokenizer(descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KVf17clbKOHx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For example, the input sequence “little girl running in field” would be split into 6 input-output pairs to train the model:\n",
        "\n",
        "X1, X2 (text sequence), y (word)\n",
        "\n",
        "photo startseq, little\n",
        "\n",
        "photo startseq, little, girl\n",
        "\n",
        "photo startseq, little, girl, running\n",
        "\n",
        "photo startseq, little, girl, running, in\n",
        "\n",
        "photo startseq, little, girl, running, in, field\n",
        "\n",
        "photo startseq, little, girl, running, in, field, endseq\n"
      ]
    },
    {
      "metadata": {
        "id": "um9aol_DKQef",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Y creamos las secuencias:\n",
        "\n",
        "# create sequences of images, input sequences and output words for an image\n",
        "def create_sequences(tokenizer, desc, image, max_length):\n",
        "\tXimages, XSeq, y = list(), list(),list()\n",
        "\tvocab_size = len(tokenizer.word_index) + 1\n",
        "\t# integer encode the description\n",
        "\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\t# split one sequence into multiple X,y pairs\n",
        "\tfor i in range(1, len(seq)):\n",
        "\t\t# select\n",
        "\t\tin_seq, out_seq = seq[:i], seq[i]\n",
        "\t\t# pad input sequence\n",
        "\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t# encode output sequence\n",
        "\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\t\t# store\n",
        "\t\tXimages.append(image)\n",
        "\t\tXSeq.append(in_seq)\n",
        "\t\ty.append(out_seq)\n",
        "\t# Ximages, XSeq, y = array(Ximages), array(XSeq), array(y)\n",
        "\treturn [Ximages, XSeq, y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fv4Tzc0WKX1r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define the captioning model\n",
        "def define_model(vocab_size, max_length):\n",
        "\t# feature extractor (encoder)\n",
        "\tinputs1 = Input(shape=(7, 7, 512))\n",
        "\tfe1 = GlobalMaxPooling2D()(inputs1)\n",
        "\tfe2 = Dense(128, activation='relu')(fe1)\n",
        "\tfe3 = RepeatVector(max_length)(fe2)\n",
        "\t# embedding\n",
        "\tinputs2 = Input(shape=(max_length,))\n",
        "\temb2 = Embedding(vocab_size, 50, mask_zero=True)(inputs2)\n",
        "\temb3 = LSTM(256, return_sequences=True)(emb2)\n",
        "\temb4 = TimeDistributed(Dense(128, activation='relu'))(emb3)\n",
        "\t# merge inputs\n",
        "\tmerged = concatenate([fe3, emb4])\n",
        "\t# language model (decoder)\n",
        "\tlm2 = LSTM(500)(merged)\n",
        "\tlm3 = Dense(500, activation='relu')(lm2)\n",
        "\toutputs = Dense(vocab_size, activation='softmax')(lm3)\n",
        "\t# tie it together [image, seq] [word]\n",
        "\tmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\tprint(model.summary())\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BXGWYHeJKfoL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# data generator, intended to be used in a call to model.fit_generator()\n",
        "def data_generator(descriptions, features, tokenizer, max_length, n_step):\n",
        "\t# loop until we finish training\n",
        "\twhile 1:\n",
        "\t\t# loop over photo identifiers in the dataset\n",
        "\t\tkeys = list(descriptions.keys())\n",
        "\t\tfor i in range(0, len(keys), n_step):\n",
        "\t\t\tXimages, XSeq, y = list(), list(),list()\n",
        "\t\t\tfor j in range(i, min(len(keys), i+n_step)):\n",
        "\t\t\t\timage_id = keys[j]\n",
        "\t\t\t\t# retrieve photo feature input\n",
        "\t\t\t\timage = features[image_id][0]\n",
        "\t\t\t\t# retrieve text input\n",
        "\t\t\t\tdesc = descriptions[image_id]\n",
        "\t\t\t\t# generate input-output pairs\n",
        "\t\t\t\tin_img, in_seq, out_word = create_sequences(tokenizer, desc, image, max_length)\n",
        "\t\t\t\tfor k in range(len(in_img)):\n",
        "\t\t\t\t\tXimages.append(in_img[k])\n",
        "\t\t\t\t\tXSeq.append(in_seq[k])\n",
        "\t\t\t\t\ty.append(out_word[k])\n",
        "\t\t\t# yield this batch of samples to the model\n",
        "\t\t\tyield [[array(Ximages), array(XSeq)], array(y)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BCWV75DwKk8U",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        " \n",
        "# generate a description for an image\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "\t# seed the generation process\n",
        "\tin_text = 'startseq'\n",
        "\t# iterate over the whole length of the sequence\n",
        "\tfor i in range(max_length):\n",
        "\t\t# integer encode input sequence\n",
        "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# pad input\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\t# predict next word\n",
        "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
        "\t\t# convert probability to integer\n",
        "\t\tyhat = argmax(yhat)\n",
        "\t\t# map integer to word\n",
        "\t\tword = word_for_id(yhat, tokenizer)\n",
        "\t\t# stop if we cannot map the word\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\t# append as input for generating the next word\n",
        "\t\tin_text += ' ' + word\n",
        "\t\t# stop if we predict the end of the sequence\n",
        "\t\tif word == 'endseq':\n",
        "\t\t\tbreak\n",
        "\treturn in_text\n",
        " \n",
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\t# step over the whole set\n",
        "\tfor key, desc in descriptions.items():\n",
        "\t\t# generate description\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\t# store actual and predicted\n",
        "\t\tactual.append([desc.split()])\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\t# calculate BLEU score\n",
        "\tbleu = corpus_bleu(actual, predicted)\n",
        "\treturn bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iHWhrLCxK2Bi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Como hemos entrenado con datasets muy pequeños, nuestro dataset tiene gran variabilidad. Con lo cual, vamos a ejecutar 3 rondas de experimentos (n_repeats) y a promediar las métricas para poder dar una métrica más fiable."
      ]
    },
    {
      "metadata": {
        "id": "Fs9KIQCLK23E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# load dev set\n",
        "filename = 'Flickr_8k.devImages.txt'\n",
        "dataset = load_set(filename)\n",
        "print('Dataset: %d' % len(dataset))\n",
        "# train-test split\n",
        "train, test = train_test_split(dataset)\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
        "print('Descriptions: train=%d, test=%d' % (len(train_descriptions), len(test_descriptions)))\n",
        "# photo features\n",
        "train_features = load_photo_features('features.pkl', train)\n",
        "test_features = load_photo_features('features.pkl', test)\n",
        "print('Photos: train=%d, test=%d' % (len(train_features), len(test_features)))\n",
        "# prepare tokenizer\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "# determine the maximum sequence length\n",
        "max_length = max(len(s.split()) for s in list(train_descriptions.values()))\n",
        "print('Description Length: %d' % max_length)\n",
        " \n",
        "# define experiment\n",
        "model_name = 'baseline1'\n",
        "verbose = 1\n",
        "n_epochs = 50\n",
        "n_photos_per_update = 2\n",
        "n_batches_per_epoch = int(len(train) / n_photos_per_update)\n",
        "n_repeats = 3\n",
        " \n",
        "# run experiment\n",
        "train_results, test_results = list(), list()\n",
        "for i in range(n_repeats):\n",
        "\t# define the model\n",
        "\tmodel = define_model(vocab_size, max_length)\n",
        "\t# fit model\n",
        "\tmodel.fit_generator(data_generator(train_descriptions, train_features, tokenizer, max_length, n_photos_per_update), steps_per_epoch=n_batches_per_epoch, epochs=n_epochs, verbose=verbose)\n",
        "\t# evaluate model on training data\n",
        "\ttrain_score = evaluate_model(model, train_descriptions, train_features, tokenizer, max_length)\n",
        "\ttest_score = evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)\n",
        "\t# store\n",
        "\ttrain_results.append(train_score)\n",
        "\ttest_results.append(test_score)\n",
        "\tprint('>%d: train=%f test=%f' % ((i+1), train_score, test_score))\n",
        "# save results to file\n",
        "df = DataFrame()\n",
        "df['train'] = train_results\n",
        "df['test'] = test_results\n",
        "print(df.describe())\n",
        "df.to_csv(model_name+'.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AN34_0c3LLE6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fijaos que nos da unas pérdidas medias son 0.02 en train y 0.05 en test. La verdad es que esto no nos dice mucho, así que vamos a probar a ejecutarlo viendo realmente lo que predice nuestra red LSTM:"
      ]
    },
    {
      "metadata": {
        "id": "v9pqWO6lLL8l",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\t# step over the whole set\n",
        "\tfor key, desc in descriptions.items():\n",
        "\t\t# generate description\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\t# store actual and predicted\n",
        "\t\tactual.append([desc.split()])\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\t\tprint('Actual:    %s' % desc)\n",
        "\t\tprint('Predicted: %s' % yhat)\n",
        "\t\tif len(actual) >= 5:\n",
        "\t\t\tbreak\n",
        "\t# calculate BLEU score\n",
        "\tbleu = corpus_bleu(actual, predicted)\n",
        "\treturn bleu\n",
        "\n",
        "# define experiment\n",
        "model_name = 'baseline1'\n",
        "verbose = 2\n",
        "n_epochs = 50\n",
        "n_photos_per_update = 2\n",
        "n_batches_per_epoch = int(len(train) / n_photos_per_update)\n",
        "n_repeats = 3\n",
        " \n",
        "# run experiment\n",
        "train_results, test_results = list(), list()\n",
        "for i in range(n_repeats):\n",
        "\t# define the model\n",
        "\tmodel = define_model(vocab_size, max_length)\n",
        "\t# fit model\n",
        "\tmodel.fit_generator(data_generator(train_descriptions, train_features, tokenizer, max_length, n_photos_per_update), steps_per_epoch=n_batches_per_epoch, epochs=n_epochs, verbose=verbose)\n",
        "\t# evaluate model on training data\n",
        "\ttrain_score = evaluate_model(model, train_descriptions, train_features, tokenizer, max_length)\n",
        "\ttest_score = evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)\n",
        "\t# store\n",
        "\ttrain_results.append(train_score)\n",
        "\ttest_results.append(test_score)\n",
        "\tprint('>%d: train=%f test=%f' % ((i+1), train_score, test_score))\n",
        "# save results to file\n",
        "df = DataFrame()\n",
        "df['train'] = train_results\n",
        "df['test'] = test_results\n",
        "print(df.describe())\n",
        "df.to_csv(model_name+'.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}